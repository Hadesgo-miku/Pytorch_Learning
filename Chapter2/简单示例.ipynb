{
 "cells": [
  {
   "cell_type": "code",
   "id": "4039af0780c71c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T09:26:35.670566Z",
     "start_time": "2025-03-22T09:26:34.751269Z"
    }
   },
   "source": [
    "#如下为关于TensorDataset/Dataloader的使用\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# 创建简单的特征张量\n",
    "# 这里创建了一个形状为 (4, 2) 的特征张量，代表 4 个样本，每个样本有 2 个特征\n",
    "features = torch.tensor([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0],\n",
    "    [7.0, 8.0]\n",
    "])\n",
    "\n",
    "# 创建对应的标签张量\n",
    "# 这里创建了一个形状为 (4,) 的标签张量，代表 4 个样本的标签\n",
    "labels = torch.tensor([0, 1, 0, 1])\n",
    "\n",
    "# 将特征张量和标签张量组合成一个元组\n",
    "data_arrays = (features, labels)\n",
    "print(data_arrays)\n",
    "# 使用 TensorDataset 组合多个张量成一个数据集\n",
    "# 这里进行了解包操作，将 data_arrays 中的每个张量作为独立参数传入\n",
    "dataset = data.TensorDataset(*data_arrays)\n",
    "print(f\"dataset类型: {type(dataset)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]]), tensor([0, 1, 0, 1]))\n",
      "dataset类型: <class 'torch.utils.data.dataset.TensorDataset'>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TensorDataset构造函数的输入\n",
    "#### torch.utils.data.TensorDataset 类的构造函数接收多个 PyTorch 张量作为输入，这些张量需要满足以下条件：\n",
    "\n",
    "- 类型：输入必须是 torch.Tensor 类型的对象。\n",
    "- 第一维长度一致：所有输入张量的第一个维度（通常表示样本数量）的长度必须相同。这是因为 TensorDataset 会按照相同的索引来组合这些张量中的元素，从而形成一个个样本。"
   ],
   "id": "20b03a12de6a4dbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q：\n",
    "####  我看到事实上我的features和labels的形状并不能横向拼接在一起，这会有影响吗\n",
    "### A:\n",
    "#### 在使用 torch.utils.data.TensorDataset 组合 features 和 labels 时，它们不需要在形状上能够横向拼接，只要它们的第一个维度（样本数量）相同就不会有影响"
   ],
   "id": "ae22727fa0e8754d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T09:26:35.684228Z",
     "start_time": "2025-03-22T09:26:35.681202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 访问数据集中的第一个样本\n",
    "print(dataset[0])\n",
    "#如果dataset创建时传入多个张量，那么dataset[0]返回的是一个元组，元组中的每个元素对应一个张量的 第一个维度\n",
    "\n",
    "sample_features, sample_label = dataset[0]\n",
    "print(f\"第一个样本的特征: {sample_features}\")\n",
    "print(f\"第一个样本的标签: {sample_label}\")"
   ],
   "id": "ac96431a5025781d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 2.]), tensor(0))\n",
      "第一个样本的特征: tensor([1., 2.])\n",
      "第一个样本的标签: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q：\n",
    "####  DataLoader的作用在哪里\n",
    "### A:\n",
    "#### DataLoader 是一种管理内存的好方法，尤其在处理大规模数据集时，它具有以下几个优势有助于内存管理\n",
    "- 批量加载数据：DataLoader 允许你将数据分成小批量，这对于处理大规模数据集非常有用。这意味着你可以在每次迭代中处理一部分数据，而不是一次性加载整个数据集，从而减少内存的使用。\n",
    "- 多线程加载数据：DataLoader 可以使用多个线程同时加载数据，从而加速数据的读取过程，特别是当数据集很大时。"
   ],
   "id": "e41dc965ebc7380a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T09:26:35.703867Z",
     "start_time": "2025-03-22T09:26:35.695474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 DataLoader 对数据集进行批量加载\n",
    "# 这里设置批量大小为 2，即每次加载 2 个样本\n",
    "batch_size = 2\n",
    "data_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#每次遍历都会重新打乱数据\n",
    "# 遍历数据加载器\n",
    "for batch_features, batch_labels in data_loader:\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"批次特征: \\n{batch_features}\")\n",
    "    print(f\"批次标签: \\n{batch_labels}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "批次特征: \n",
      "tensor([[5., 6.],\n",
      "        [3., 4.]])\n",
      "批次标签: \n",
      "tensor([0, 1])\n",
      "------------------------------\n",
      "批次特征: \n",
      "tensor([[1., 2.],\n",
      "        [7., 8.]])\n",
      "批次标签: \n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q：\n",
    "####  两次用for对DataLoader的迭代是不是不会互相影响，但如果将其变为迭代器就会统一记录次数\n",
    "### A:\n",
    "#### 你说得对。使用 for 循环两次迭代 DataLoader 时，每次迭代都是独立的，不会相互影响；而如果将 DataLoader 转换为迭代器（iterator），迭代状态会被记录，迭代次数会统一计数。\n",
    "\n"
   ],
   "id": "846a67649d1987ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T09:27:33.858647Z",
     "start_time": "2025-03-22T09:27:33.847160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_iter=iter(data_loader)\n",
    "next(data_iter)"
   ],
   "id": "2f7a038643984cea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 2.],\n",
       "         [5., 6.]]),\n",
       " tensor([0, 0])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
